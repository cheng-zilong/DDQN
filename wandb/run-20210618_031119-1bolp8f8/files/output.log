1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
(Collecting Data) ep=     0 ep_reward_last=0.00 ep_reward_avg=0.00 ep_steps= 112 total_steps=    113 loss=0.0000 eps=1.0000 fps=418.97
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
(Collecting Data) ep=     1 ep_reward_last=0.00 ep_reward_avg=0.00 ep_steps= 115 total_steps=    228 loss=0.0000 eps=1.0000 fps=319.27
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
(Collecting Data) ep=     2 ep_reward_last=2.00 ep_reward_avg=0.67 ep_steps= 188 total_steps=    416 loss=0.0000 eps=1.0000 fps=344.83
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
(Collecting Data) ep=     3 ep_reward_last=3.00 ep_reward_avg=1.25 ep_steps= 214 total_steps=    630 loss=0.0000 eps=1.0000 fps=398.80
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
(Collecting Data) ep=     4 ep_reward_last=0.00 ep_reward_avg=1.00 ep_steps= 113 total_steps=    743 loss=0.0000 eps=1.0000 fps=391.69
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
Process ReplayBufferAsync-2:
Traceback (most recent call last):
  File "/home/chengzilong/anaconda3/envs/myenv/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/chengzilong/DDQN/ReplayBufferAsync2.py", line 43, in run
    state_share = torch.zeros((self.cache_size, *state.shape), dtype=state.dtype, device=torch.device(0)).share_memory_()
TypeError: zeros() received an invalid combination of arguments - got (tuple, device=torch.device, dtype=numpy.dtype[uint8]), but expected one of:
 * (tuple of ints size, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)
 * (tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
(Collecting Data) ep=     5 ep_reward_last=1.00 ep_reward_avg=1.00 ep_steps= 143 total_steps=    886 loss=0.0000 eps=1.0000 fps=263.57
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
