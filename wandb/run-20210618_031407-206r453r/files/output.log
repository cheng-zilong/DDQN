1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
(Collecting Data) ep=     0 ep_reward_last=3.00 ep_reward_avg=3.00 ep_steps= 235 total_steps=    236 loss=0.0000 eps=1.0000 fps=371.70
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
(Collecting Data) ep=     1 ep_reward_last=2.00 ep_reward_avg=2.50 ep_steps= 187 total_steps=    423 loss=0.0000 eps=1.0000 fps=333.91
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
(Collecting Data) ep=     2 ep_reward_last=3.00 ep_reward_avg=2.67 ep_steps= 254 total_steps=    677 loss=0.0000 eps=1.0000 fps=369.36
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
(Collecting Data) ep=     3 ep_reward_last=0.00 ep_reward_avg=2.00 ep_steps= 111 total_steps=    788 loss=0.0000 eps=1.0000 fps=314.80
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
(Collecting Data) ep=     4 ep_reward_last=2.00 ep_reward_avg=2.00 ep_steps= 210 total_steps=    998 loss=0.0000 eps=1.0000 fps=306.40
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
1 0 4
Process ReplayBufferAsync-2:
Traceback (most recent call last):
  File "/home/chengzilong/anaconda3/envs/myenv/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/chengzilong/DDQN/ReplayBufferAsync2.py", line 79, in run
    state_share[self.in_pointer] = torch.tensor(state, device=torch.device(0))
IndexError: index 7 is out of bounds for dimension 0 with size 5
1 1 5
1 1 5
1 1 5
1 1 5
1 1 5
2 3 5
2 3 5
2 3 5
2 3 5
2 3 5
3 7 5
3 7 5
3 7 5
3 7 5
